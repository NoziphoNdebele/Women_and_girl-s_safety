{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8764321,"sourceType":"datasetVersion","datasetId":5266074}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Project Title: AI-Driven Solution for Gender Equality: Addressing Domestic Violence Against Women\n#### Done By: Nozipho Sithembiso Ndebele\n\n<div style=\"text-align: center;\">\r\n<img src=\"https://slamatlaw.co.za/wp-content/uploads/2021/03/domestic-violence.jpg\" alt=\"Anime Image\" width=\"800\"/>\r\n</div>\n---\n\n## Table of Contents\n\n<a href=#BC> Background Context</a>\n\n<a href=#one>1. Importing Packages</a>\n\n<a href=#two>2. Data Collection and Description</a>\n\n<a href=#three>3. Loading Data </a>\n\n<a href=#four>4. Data Cleaning and Filtering</a>\n\n<a href=#five>5. Exploratory Data Analysis (EDA)</a>\n\n<a href=#six>6. Modeling </a>\n\n<a href=#seven>7. Evaluation and Validation</a>\n\n<a href=#eight>8. Final Model</a>\n\n<a href=#nine>9. Conclusion and Future Work</a>\n\n<a href=#ten>10. References</a>","metadata":{}},{"cell_type":"markdown","source":"---\n <a id=\"BC\"></a>\n## **Background Context**\n\n### Purpose\nThis project leverages AI technologies to address the pressing issue of domestic violence against women, particularly in rural areas of developing countries. Domestic violence remains a critical barrier to achieving gender equality as outlined in UN SDG 5, affecting womenâ€™s physical, mental, and economic well-being. The aim is to explore the socio-economic factors that contribute to domestic violence and develop an AI-powered solution that can help predict and prevent these incidents. By uncovering patterns and correlations through machine learning, this project aims to empower policy-makers, community leaders, and support services to take proactive action against domestic violence.\n\n### Significance\nThrough AI-driven analysis of socio-economic data such as education, employment, income, and marital status, this project seeks to provide data-driven insights that inform strategies to support vulnerable women and mitigate domestic violence. The AI model will help uncover patterns that can be used to design targeted interventions, improving community safety, empowering women, and contributing to broader efforts to promote gender equality.\n\n### Problem Domain\nDomestic violence against women, especially in rural and developing regions, often goes unreported due to economic dependency, cultural barriers, and societal norms. Using machine learning models to analyze the National Income Dynamics Study (NIDS) 2017, Wave 5 dataset, the project will uncover relationships between key socio-economic variables and domestic violence. The insights gained can be scaled to other similar communities, contributing to global efforts to reduce violence against women and girls.\n\n### Challenges\n* **Data Analysis Complexity:** Identifying the socio-economic factors that contribute to domestic violence requires advanced AI techniques, such as natural language processing, predictive modeling, and classification. Ensuring these models are both accurate and actionable is crucial.\n* **Cultural Sensitivity:** Any AI-driven intervention must be culturally adaptable, addressing local contexts while being scalable across regions.\n* **Actionable Insights:** The solution must translate AI-driven findings into practical recommendations for policy-makers and community leaders, ensuring the impact extends beyond theoretical analysis.\n\n### Key Questions\n* How does education level correlate with the likelihood of experiencing domestic violence?\n* How do employment and income levels influence the risk of domestic violence?\n* Does marital status play a significant role in the incidence of domestic violence?\n* Which age groups are most vulnerable to domestic violence, and how can preventive measures be applied through AI insights?\n\n---","metadata":{}},{"cell_type":"markdown","source":"---\n<a href=#one></a>\n## **Importing Packages**\n\n### Purpose\nTo set up the Python environment with the necessary libraries and tools required for data manipulation, visualization, and modeling. The following packages will be used throughout the project to ensure smooth data processing and analysis.\n\n### Details\n* Pandas: For data manipulation and analysis.\n* NumPy: For numerical computations and handling arrays.\n* Matplotlib/Seaborn: For data visualization to help in understanding trends and patterns.\n* scikit-learn: For building and evaluating machine learning models.\n* Statsmodels: For statistical modeling and hypothesis testing.\n\n---","metadata":{}},{"cell_type":"code","source":"# Import necessary packages\n\n# Data manipulation and analysis\nimport pandas as pd  # Pandas for data manipulation\nimport numpy as np  # NumPy for numerical computations\n\n# Data visualization\nimport matplotlib.pyplot as plt  # Matplotlib for plotting\nimport seaborn as sns  # Seaborn for statistical data visualization\nimport plotly.express as px  # Plotly Express for interactive plots\nimport plotly.graph_objects as go  # Plotly Graph Objects for detailed visualizations\n\n# Machine Learning\nfrom sklearn.model_selection import train_test_split  # For splitting data into training and testing sets\n\n# Statistical analysis\nimport statsmodels.api as sm  # Statsmodels for statistical modeling\n\n# Configure visualization settings\nsns.set(style='whitegrid')  # Set the default style for Seaborn plots\nplt.rcParams['figure.figsize'] = (10, 6)  # Set default figure size for Matplotlib\n\n# Import the warnings module and filter warnings to ignore all warning messages\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-23T15:10:37.009790Z","iopub.execute_input":"2024-10-23T15:10:37.010402Z","iopub.status.idle":"2024-10-23T15:10:37.020933Z","shell.execute_reply.started":"2024-10-23T15:10:37.010355Z","shell.execute_reply":"2024-10-23T15:10:37.019615Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"---\n<a href=#two></a>\n## **Data Collection and Description**\n### Purpose\nThis section outlines how the data was collected and provides a general overview of its characteristics. Understanding the data's origin, size, and types of variables is crucial for performing effective analysis and drawing meaningful insights.\n\n### Details\nThe dataset was collected as part of a study on domestic violence against women in a specific rural area of a developing country. The data collection was done through surveys distributed to women in the area, focusing on socio-economic factors such as age, education, employment, income, marital status, and experiences of domestic violence.\n* Source: The data is provided as part of a research initiative aimed at understanding the socio-economic factors contributing to domestic violence in rural communities of developing countries.\n* Method of Collection: The data was collected through surveys conducted by local field researchers. Respondents were asked to provide information on their age, education level, employment status, income, marital status, and whether they had experienced domestic violence.\n* Dataset Characteristics:\n * Size: The dataset contains several hundred records, each representing an individual respondent.\n\n * Scope: The data focuses on socio-economic factors and domestic violence in a rural area, making it specific to that context. The analysis will help generalize findings to similar communities.\n *  Types of Data: The dataset includes both numerical and categorical variables.\n\n---","metadata":{}},{"cell_type":"markdown","source":"---\n<a href=#three></a>\n## **Loading Data**\n### Purpose\nThe purpose of this section is to load the dataset into the notebook for further manipulation and analysis. This is the first step in working with the data, and it allows us to inspect the raw data and get a sense of its structure.\n\n### Details\nIn this section, we will load the dataset into a Pandas DataFrame and display the first few rows to understand what the raw data looks like. This will help in planning the next steps of data cleaning and analysis.\n\n\n---","metadata":{}},{"cell_type":"code","source":"# Load the dataset into a Pandas DataFrame\n\n# The dataset is stored in a CSV file named 'Domestic violence.csv'\ndf = pd.read_csv('/kaggle/input/domestic-violence-against-women/Domestic violence.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-23T15:10:37.023653Z","iopub.execute_input":"2024-10-23T15:10:37.024153Z","iopub.status.idle":"2024-10-23T15:10:37.055997Z","shell.execute_reply.started":"2024-10-23T15:10:37.024081Z","shell.execute_reply":"2024-10-23T15:10:37.054620Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# df is the original dataset (DataFrame), this creates a copy of it\ndf_copy = df.copy()\n\n# Now 'df_copy' is an independent copy of 'df'. Changes to 'df_copy' won't affect 'df'.\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-23T15:10:37.057576Z","iopub.execute_input":"2024-10-23T15:10:37.058082Z","iopub.status.idle":"2024-10-23T15:10:37.064773Z","shell.execute_reply.started":"2024-10-23T15:10:37.058023Z","shell.execute_reply":"2024-10-23T15:10:37.063208Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Display the first few rows of the dataset to get a sense of what the raw data looks like\ndf_copy.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-23T15:10:37.068213Z","iopub.execute_input":"2024-10-23T15:10:37.068905Z","iopub.status.idle":"2024-10-23T15:10:37.091947Z","shell.execute_reply.started":"2024-10-23T15:10:37.068844Z","shell.execute_reply":"2024-10-23T15:10:37.090640Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"   SL. No  Age Education  Employment   Income Marital status  Violence \n0       1   30  secondary  unemployed       0         married       yes\n1       2   47   tertiary  unemployed       0         married        no\n2       3   24   tertiary  unemployed       0        unmarred        no\n3       4   22   tertiary  unemployed       0        unmarred        no\n4       5   50    primary  unemployed       0         married       yes","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SL. No</th>\n      <th>Age</th>\n      <th>Education</th>\n      <th>Employment</th>\n      <th>Income</th>\n      <th>Marital status</th>\n      <th>Violence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>30</td>\n      <td>secondary</td>\n      <td>unemployed</td>\n      <td>0</td>\n      <td>married</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>47</td>\n      <td>tertiary</td>\n      <td>unemployed</td>\n      <td>0</td>\n      <td>married</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>24</td>\n      <td>tertiary</td>\n      <td>unemployed</td>\n      <td>0</td>\n      <td>unmarred</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>22</td>\n      <td>tertiary</td>\n      <td>unemployed</td>\n      <td>0</td>\n      <td>unmarred</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>50</td>\n      <td>primary</td>\n      <td>unemployed</td>\n      <td>0</td>\n      <td>married</td>\n      <td>yes</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"# Display the number of rows and columns in the dataset to understand its size\ndf_copy.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-23T15:10:37.093846Z","iopub.execute_input":"2024-10-23T15:10:37.094426Z","iopub.status.idle":"2024-10-23T15:10:37.108931Z","shell.execute_reply.started":"2024-10-23T15:10:37.094372Z","shell.execute_reply":"2024-10-23T15:10:37.107690Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"(347, 7)"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"# Check the structure of the dataset\ndf_copy.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-23T15:10:37.110863Z","iopub.execute_input":"2024-10-23T15:10:37.111411Z","iopub.status.idle":"2024-10-23T15:10:37.130940Z","shell.execute_reply.started":"2024-10-23T15:10:37.111350Z","shell.execute_reply":"2024-10-23T15:10:37.129361Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 347 entries, 0 to 346\nData columns (total 7 columns):\n #   Column           Non-Null Count  Dtype \n---  ------           --------------  ----- \n 0   SL. No           347 non-null    int64 \n 1   Age              347 non-null    int64 \n 2   Education        347 non-null    object\n 3   Employment       347 non-null    object\n 4   Income           347 non-null    int64 \n 5   Marital status   347 non-null    object\n 6   Violence         347 non-null    object\ndtypes: int64(3), object(4)\nmemory usage: 19.1+ KB\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"---\r\n<a href=#four></a>\r\n## **Data Cleaning and Filtering**\r\nBefore analyzing the data, it is crucial to clean and filter it. This process involves handling missing values, removing outliers, correcting errors, and possibly reducing the data by filtering out irrelevant features. These steps ensure that the analysis is based on accurate and reliable data.\r\n\r\nDetails\r\nIn this section, we will:\r\n\r\n* Check for Missing Values: Identify if there are any missing values in the dataset and handle them accordingly.\r\n* Remove Duplicates: Ensure there are no duplicate rows that could skew the analysis.\r\n* Correct Errors: Look for and correct any obvious data entry errors.\r\n* Filter Data: Depending on the analysis requirements, filter the data to include only relevant rltering**\n\n---","metadata":{}},{"cell_type":"code","source":"# 1. Check for missing values in the dataset\n\ndef check_missing_values(df):\n    \"\"\"\n    Check for missing values in the dataset and display the number of missing values per column.\n\n    Parameters:\n    df (pandas.DataFrame): The dataset to check for missing values.\n\n    Returns:\n    pandas.Series: A series showing the number of missing values for each column.\n    \"\"\"\n     # Check for missing values in the dataset and display them\n    print(\"Missing values per column:\")\n    missing_values = df.isnull().sum()\n    print(missing_values)\n    return missing_values\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-23T15:10:37.132869Z","iopub.execute_input":"2024-10-23T15:10:37.133424Z","iopub.status.idle":"2024-10-23T15:10:37.146979Z","shell.execute_reply.started":"2024-10-23T15:10:37.133366Z","shell.execute_reply":"2024-10-23T15:10:37.145530Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# df is your DataFrame\nmissing_values = check_missing_values(df_copy)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-23T15:10:37.148898Z","iopub.execute_input":"2024-10-23T15:10:37.149438Z","iopub.status.idle":"2024-10-23T15:10:37.169598Z","shell.execute_reply.started":"2024-10-23T15:10:37.149380Z","shell.execute_reply":"2024-10-23T15:10:37.168293Z"}},"outputs":[{"name":"stdout","text":"Missing values per column:\nSL. No             0\nAge                0\nEducation          0\nEmployment         0\nIncome             0\nMarital status     0\nViolence           0\ndtype: int64\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"After examining the dataset, no missing values were found across any of the columns. This ensures data completeness and eliminates the need for imputation or further cleaning related to missing data.\r\n","metadata":{}},{"cell_type":"code","source":"#2. Check for duplicate rows\ndef remove_duplicates(df):\n    \"\"\"\n    Checks for duplicate rows in the dataset and removes them if any are found.\n\n    Args:\n    df (pandas.DataFrame): The dataframe to check for duplicate rows.\n\n    Returns:\n    pandas.DataFrame: The dataframe with duplicate rows removed, if any existed.\n    \"\"\"\n    # Check for duplicate rows\n    duplicate_rows = df.duplicated().sum()\n    print(f\"\\nNumber of duplicate rows: {duplicate_rows}\")\n    \n    # Remove duplicates if any exist\n    if duplicate_rows > 0:\n        df.drop_duplicates(inplace=True)\n        print(f\"Duplicate rows removed. Updated dataframe has {len(df)} rows.\")\n    else:\n        print(\"No duplicate rows found.\")\n    \n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-23T15:10:37.175087Z","iopub.execute_input":"2024-10-23T15:10:37.176603Z","iopub.status.idle":"2024-10-23T15:10:37.185928Z","shell.execute_reply.started":"2024-10-23T15:10:37.176556Z","shell.execute_reply":"2024-10-23T15:10:37.184470Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"df_copy = remove_duplicates(df_copy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-23T15:10:37.187486Z","iopub.execute_input":"2024-10-23T15:10:37.187922Z","iopub.status.idle":"2024-10-23T15:10:37.204033Z","shell.execute_reply.started":"2024-10-23T15:10:37.187879Z","shell.execute_reply":"2024-10-23T15:10:37.202656Z"}},"outputs":[{"name":"stdout","text":"\nNumber of duplicate rows: 0\nNo duplicate rows found.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"Upon reviewing the dataset, no duplicate rows were found. This ensures that all records are unique, and no further action is required for data deduplication.\r\n","metadata":{}},{"cell_type":"code","source":"# 3. Rename the columns according to PEP 8 naming conventions\n\ndef rename_columns(df):\n    \"\"\"\n    Renames the columns of the dataframe according to PEP 8 naming conventions.\n\n    Args:\n    df (pandas.DataFrame): The dataframe with original column names.\n\n    Returns:\n    pandas.DataFrame: The dataframe with updated column names following PEP 8 naming conventions.\n    \"\"\"\n    # Rename columns according to PEP 8 naming conventions\n    df.rename(columns={\n        'SL. No': 'serial_no',\n        'Age': 'age',\n        'Education': 'education',\n        'Employment': 'employment',\n        'Income': 'income',\n        'Marital status': 'marital_status',\n        'Violence': 'violence'\n    }, inplace=True)\n    \n    # Display the updated column names to confirm the changes\n    print(\"Updated column names in the DataFrame:\")\n    print(df.columns)\n    \n    return df\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-23T15:10:37.206042Z","iopub.execute_input":"2024-10-23T15:10:37.207018Z","iopub.status.idle":"2024-10-23T15:10:37.214841Z","shell.execute_reply.started":"2024-10-23T15:10:37.206959Z","shell.execute_reply":"2024-10-23T15:10:37.213639Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"This function renames the columns to follow PEP 8 naming conventions and prints the updated column names for confirmation.","metadata":{}},{"cell_type":"code","source":"df_copy = rename_columns(df_copy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-23T15:10:37.216539Z","iopub.execute_input":"2024-10-23T15:10:37.217112Z","iopub.status.idle":"2024-10-23T15:10:37.233942Z","shell.execute_reply.started":"2024-10-23T15:10:37.216989Z","shell.execute_reply":"2024-10-23T15:10:37.232460Z"}},"outputs":[{"name":"stdout","text":"Updated column names in the DataFrame:\nIndex(['serial_no', 'age', 'Education ', 'Employment ', 'income',\n       'Marital status ', 'Violence '],\n      dtype='object')\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# 4. Rename columns to follow PEP 8 conventions and remove leading/trailing spaces\ndef clean_column_names(df):\n    \"\"\"\n    Cleans the column names of the dataframe by removing leading/trailing spaces, \n    converting them to lowercase, replacing spaces with underscores, and ensuring PEP 8 conventions.\n\n    Args:\n    df (pandas.DataFrame): The dataframe with original column names.\n\n    Returns:\n    pandas.DataFrame: The dataframe with cleaned column names following PEP 8 naming conventions.\n    \"\"\"\n    # Standardize column names\n    df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\n    \n    # Display the updated column names to confirm the changes\n    print(\"Updated column names in the DataFrame:\")\n    print(df.columns)\n    \n    return df\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-23T15:10:37.235655Z","iopub.execute_input":"2024-10-23T15:10:37.236162Z","iopub.status.idle":"2024-10-23T15:10:37.247392Z","shell.execute_reply.started":"2024-10-23T15:10:37.236085Z","shell.execute_reply":"2024-10-23T15:10:37.246064Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"df_copy = clean_column_names(df_copy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-23T15:10:37.248956Z","iopub.execute_input":"2024-10-23T15:10:37.249448Z","iopub.status.idle":"2024-10-23T15:10:37.263215Z","shell.execute_reply.started":"2024-10-23T15:10:37.249407Z","shell.execute_reply":"2024-10-23T15:10:37.261785Z"}},"outputs":[{"name":"stdout","text":"Updated column names in the DataFrame:\nIndex(['serial_no', 'age', 'education', 'employment', 'income',\n       'marital_status', 'violence'],\n      dtype='object')\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"This function removes any leading/trailing spaces, converts names to lowercase, replaces spaces with underscores, and prints the updated column names.","metadata":{}},{"cell_type":"code","source":"# 5. Correct any errors in the data\n\ndef correct_data_errors(df):\n    \"\"\"\n    Checks for inconsistencies in the categorical columns and corrects known errors in the data.\n    \n    Specifically:\n    - Displays unique values in 'marital_status' and 'violence' columns.\n    - Corrects known spelling errors in the 'marital_status' column (e.g., 'unmarred' -> 'unmarried').\n\n    Args:\n    df (pandas.DataFrame): The dataframe to check and correct.\n\n    Returns:\n    pandas.DataFrame: The dataframe with corrected categorical data.\n    \"\"\"\n    # Check for inconsistencies in 'marital_status' and 'violence' columns\n    print(\"\\nUnique values in 'marital_status':\")\n    print(df['marital_status'].unique())\n\n    print(\"\\nUnique values in 'violence':\")\n    print(df['violence'].unique())\n\n    # Correct known spelling errors in 'marital_status'\n    df['marital_status'] = df['marital_status'].replace({'unmarred': 'unmarried'})\n    \n    return df\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-23T15:10:37.264964Z","iopub.execute_input":"2024-10-23T15:10:37.265558Z","iopub.status.idle":"2024-10-23T15:10:37.275878Z","shell.execute_reply.started":"2024-10-23T15:10:37.265514Z","shell.execute_reply":"2024-10-23T15:10:37.274566Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"df_copy = correct_data_errors(df_copy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-23T15:10:37.277127Z","iopub.execute_input":"2024-10-23T15:10:37.277589Z","iopub.status.idle":"2024-10-23T15:10:37.298990Z","shell.execute_reply.started":"2024-10-23T15:10:37.277546Z","shell.execute_reply":"2024-10-23T15:10:37.297601Z"}},"outputs":[{"name":"stdout","text":"\nUnique values in 'marital_status':\n['married' 'unmarred']\n\nUnique values in 'violence':\n['yes' 'no']\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"This function prints the unique values in the specified categorical columns and corrects the known error in the marital_status column.","metadata":{}},{"cell_type":"markdown","source":"## **Saving the Cleaned Dataset**\r\n### Purpose\r\n\r\nThis section outlines how to save the cleaned dataset for future use. Saving the dataset ensures that the data cleaning process does not need to be repeated and allows for consistent use in subsequent analyses.\r\n\r\n### Details\r\n\r\nWe will save the cleaned dataset as a CSV file.","metadata":{}},{"cell_type":"code","source":"#6. Save the cleaned dataset to a new CSV file\n\ndef save_cleaned_dataset(df, filename='cleaned_domestic_violence.csv'):\n    \"\"\"\n    Saves the cleaned dataframe to a CSV file.\n\n    Args:\n    df (pandas.DataFrame): The cleaned dataframe to save.\n    filename (str): The name of the file to save the dataframe to (default is 'cleaned_domestic_violence.csv').\n\n    Returns:\n    None\n    \"\"\"\n    # Save the cleaned dataset to a CSV file\n    df.to_csv(filename, index=False)\n    print(f\"Cleaned dataset saved successfully as '{filename}'.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-23T15:10:37.300563Z","iopub.execute_input":"2024-10-23T15:10:37.301037Z","iopub.status.idle":"2024-10-23T15:10:37.313145Z","shell.execute_reply.started":"2024-10-23T15:10:37.300983Z","shell.execute_reply":"2024-10-23T15:10:37.311702Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"save_cleaned_dataset(df_copy)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-23T15:10:37.314820Z","iopub.execute_input":"2024-10-23T15:10:37.315419Z","iopub.status.idle":"2024-10-23T15:10:37.333899Z","shell.execute_reply.started":"2024-10-23T15:10:37.315361Z","shell.execute_reply":"2024-10-23T15:10:37.332412Z"}},"outputs":[{"name":"stdout","text":"Cleaned dataset saved successfully as 'cleaned_domestic_violence.csv'.\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"---\n<a href=#five></a>\n## **Exploratory Data Analysis (EDA)**\n\n---\n","metadata":{}},{"cell_type":"code","source":"#Please use code cells to code in and do not forget to comment your code.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-23T15:10:37.335196Z","iopub.execute_input":"2024-10-23T15:10:37.335736Z","iopub.status.idle":"2024-10-23T15:10:37.342178Z","shell.execute_reply.started":"2024-10-23T15:10:37.335619Z","shell.execute_reply":"2024-10-23T15:10:37.340875Z"}},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":"---\n<a href=#six></a>\n## **Modeling**\n\n---\n","metadata":{}},{"cell_type":"code","source":"#Please use code cells to code in and do not forget to comment your code.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-23T15:10:37.343886Z","iopub.execute_input":"2024-10-23T15:10:37.344693Z","iopub.status.idle":"2024-10-23T15:10:37.353546Z","shell.execute_reply.started":"2024-10-23T15:10:37.344648Z","shell.execute_reply":"2024-10-23T15:10:37.352314Z"}},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":"---\n<a href=#seven></a>\n## **Evaluation and Validation**\n\n---","metadata":{}},{"cell_type":"code","source":"#Please use code cells to code in and do not forget to comment your code.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-23T15:10:37.355229Z","iopub.execute_input":"2024-10-23T15:10:37.355722Z","iopub.status.idle":"2024-10-23T15:10:37.366030Z","shell.execute_reply.started":"2024-10-23T15:10:37.355657Z","shell.execute_reply":"2024-10-23T15:10:37.364899Z"}},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":"---\n<a href=#eight></a>\n## **Final Model**\n\n---\n","metadata":{}},{"cell_type":"code","source":"#Please use code cells to code in and do not forget to comment your code.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-23T15:10:37.367761Z","iopub.execute_input":"2024-10-23T15:10:37.368255Z","iopub.status.idle":"2024-10-23T15:10:37.377620Z","shell.execute_reply.started":"2024-10-23T15:10:37.368210Z","shell.execute_reply":"2024-10-23T15:10:37.376270Z"}},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":"---\n<a href=#nine></a>\n## **Conclusion and Future Work**\n\n---\n","metadata":{}},{"cell_type":"code","source":"#Please use code cells to code in and do not forget to comment your code.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-23T15:10:37.378907Z","iopub.execute_input":"2024-10-23T15:10:37.379430Z","iopub.status.idle":"2024-10-23T15:10:37.390760Z","shell.execute_reply.started":"2024-10-23T15:10:37.379386Z","shell.execute_reply":"2024-10-23T15:10:37.389550Z"}},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":"---\n<a href=#ten></a>\n## **References**\n\n---","metadata":{}},{"cell_type":"code","source":"#Please use code cells to code in and do not forget to comment your code.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-23T15:10:37.395651Z","iopub.execute_input":"2024-10-23T15:10:37.396126Z","iopub.status.idle":"2024-10-23T15:10:37.403232Z","shell.execute_reply.started":"2024-10-23T15:10:37.396057Z","shell.execute_reply":"2024-10-23T15:10:37.401674Z"}},"outputs":[],"execution_count":30},{"cell_type":"markdown","source":"## Additional Sections to Consider\n\n* ### Appendix: \n\n\n* ### Contributors: \n","metadata":{}}]}